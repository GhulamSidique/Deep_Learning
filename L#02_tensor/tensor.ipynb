{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tesnsor: multi-dimensional arrays of numbers that represent complex data.\n",
    "### whenever we have input data in any format we need to convert it intfo a tensor which will contain numbers.\n",
    "### then these tensors are passed to the neural netwrok for the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, tensor(8))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a simple tensor with torch\n",
    "scalar=torch.tensor(8)\n",
    "type(scalar), scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check the number of dimensions \n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get back the tensro  or value as an integer\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([8, 7]), torch.Tensor, 1, torch.Size([2]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a vector or list\n",
    "vector=torch.tensor([8,7]) # this is the one dimensional vector\n",
    "\n",
    "# print the data\n",
    "vector, type(vector), vector.ndim, vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[8., 7.],\n",
       "         [9., 2.]]),\n",
       " torch.Tensor,\n",
       " 2,\n",
       " torch.Size([2, 2]),\n",
       " tensor(7.))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a matrix\n",
    "matrix=torch.Tensor([[8,7], [9,2]])\n",
    "\n",
    "# print\n",
    "matrix, type(matrix), matrix.ndim, matrix.shape, matrix[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [8, 5, 2]]]),\n",
       " torch.Tensor,\n",
       " 3,\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor of more than 2 dimensions\n",
    "tens=torch.tensor([[[1,2,3], [4,5,6], [8,5,2]]])\n",
    "\n",
    "# print\n",
    "tens, type(tens), tens.ndim, tens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### result: from the above tensor.size([1,3,3]) the first 1 shows the first bracket of the tensor, the second 3 shows the second bracket which contains total three more rows and the 3rd 3 shows the number of columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random tensors:\n",
    "### theese are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8404, 0.9114, 0.6551, 0.5017],\n",
       "         [0.6070, 0.1399, 0.0846, 0.4011],\n",
       "         [0.7461, 0.8456, 0.4632, 0.0856]]),\n",
       " torch.Tensor,\n",
       " torch.Size([3, 4]),\n",
       " 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random tensor\n",
    "r_tens=torch.rand(3, 4) # randopm tensor of size 3*4\n",
    "# we can give as many dimensions as we need such as (1,4,5)\n",
    "\n",
    "r_tens, type(r_tens), r_tens.shape, r_tens.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random tensor of the similar size of an image \n",
    "random_tens_image=torch.rand(size=(224, 224, 3))\n",
    "# here we have height, width and colour channel(Red, green, blue)\n",
    "# color channel can also come first as (3, 224, 224)\n",
    "  \n",
    "random_tens_image.shape, random_tens_image.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeros and ones tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]),\n",
       " torch.Size([3, 5]),\n",
       " 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zeros\n",
    "z_tens=torch.zeros(size=(3, 5))\n",
    "\n",
    "# print\n",
    "z_tens, z_tens.shape, z_tens.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]),\n",
       " torch.Size([3, 5]),\n",
       " 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ones\n",
    "o_tens=torch.ones(size=(3, 5))\n",
    "\n",
    "# print\n",
    "o_tens, o_tens.shape, o_tens.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create tensors using arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4]), torch.Size([4]), 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tesnor using arange\n",
    "range_tens=torch.arange(1, 5)# 1*5 tensor, one dimensional\n",
    "\n",
    "# print\n",
    "range_tens, range_tens.shape, range_tens.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  0,  50, 100, 150, 200, 250, 300, 350, 400, 450]),\n",
       " torch.Size([10]),\n",
       " 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using step\n",
    "step_range_tens=torch.arange(start=0, end=500, step=50)\n",
    "\n",
    "# print\n",
    "step_range_tens, step_range_tens.shape, step_range_tens.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check on which device we are currently working\n",
    "step_range_tens.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maths on tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([103., 105., 107.]),\n",
       " tensor([ 6., 10., 14.]),\n",
       " tensor([1.5000, 2.5000, 3.5000]),\n",
       " tensor([2., 4., 6.]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding to each element\n",
    "tens=torch.Tensor([3, 5, 7])\n",
    "\n",
    "# add 100 to each tensor\n",
    "after_add=tens + 100\n",
    "\n",
    "# multiply by 2\n",
    "after_mul=tens*2\n",
    "\n",
    "# divide by 2\n",
    "after_div=tens/2\n",
    "\n",
    "# subtract 1\n",
    "after_sub=tens-1\n",
    "\n",
    "# print the values\n",
    "after_add, after_mul, after_div, after_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([103., 105., 107.]),\n",
       " tensor([ 6., 10., 14.]),\n",
       " tensor([1.5000, 2.5000, 3.5000]),\n",
       " tensor([2., 4., 6.]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performing maths using pytorch as follows\n",
    "after_add=torch.add(tens, 100)\n",
    "\n",
    "# mul\n",
    "after_mul=torch.mul(tens, 2)\n",
    "\n",
    "# div\n",
    "after_div=torch.div(tens, 2)\n",
    "\n",
    "# sub\n",
    "after_sub=torch.sub(tens, 1)\n",
    "\n",
    "# print the values \n",
    "after_add, after_mul, after_div, after_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multiplication:\n",
    "### by element wise mul\n",
    "### by matrix mul as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 5., 7.]) * tensor([3., 5., 7.])\n",
      "tensor([ 9., 25., 49.])\n"
     ]
    }
   ],
   "source": [
    "# making use of the previous tens\n",
    "print(tens, \"*\", tens)\n",
    "\n",
    "# now element-wise mul\n",
    "print(tens*tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(83.)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using matmul method that performs the dotf product between two matrices and returns a scalar\n",
    "mul=torch.matmul(tens, tens) \n",
    "# we can also write mm in place of matmul\n",
    "mul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### result: manually --> 3* 3 + 5* 5 + 7*7 = 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m tens2\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mTensor([[\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m7\u001b[39m], [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m8\u001b[39m]])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# matmul\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m result\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtens1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtens2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m result\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# shape miss-match issues\n",
    "tens1=torch.tensor([[1,2], [5,6], [8,9]])\n",
    "tens2=torch.Tensor([[2,1], [5,7], [5, 8]])\n",
    "\n",
    "# matmul\n",
    "result=torch.mm(tens1, tens2)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### above error is caused by the miss match of the shape because both of the tensors are f the shape 3*2 and for multiplication we have to satisfy that columns of the first matrix must be equal to the rows of the second. and this condition is violated here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To avoid above problem let's apply transpose of a matrix method as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 67., 100.],\n",
       "         [ 79., 116.]]),\n",
       " torch.Size([2, 2]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transposing the tensor\n",
    "tens1=tens1.float() # dtype change\n",
    "t_tens1=tens1.T\n",
    "# now multiply\n",
    "result=torch.mm(t_tens1, tens2)\n",
    "result, result.shape\n",
    "# t_tens1.shape, tens2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## min, max, mean, sum etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the min is  tensor(10.) \t max  tensor(190.) \t sum  tensor(1900.) \t mean  tensor(100.)\n"
     ]
    }
   ],
   "source": [
    "# random tensor\n",
    "rn=torch.arange(10, 200, 10).float()# step of 10\n",
    "\n",
    "# above mentioned operations\n",
    "print('the min is ', torch.min(rn), \"\\t max \", torch.max(rn), \"\\t sum \", torch.sum(rn), \"\\t mean \", torch.mean(rn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the min is at  tensor(0) \t max at  tensor(18)\n"
     ]
    }
   ],
   "source": [
    "# find the values according to their index/ position\n",
    "# we make use of argmin method for min\n",
    "print('the min is at ', rn.argmin(), \"\\t max at \", rn.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min  tensor(10.)  max  tensor(190.)\n"
     ]
    }
   ],
   "source": [
    "# check the min at 0 and max qat 18\n",
    "print(\"min \", rn[0], \" max \", rn[18])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
